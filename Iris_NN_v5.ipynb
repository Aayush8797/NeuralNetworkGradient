{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c222bdd2-91f3-4363-bde7-778caec66877",
    "_execution_state": "idle",
    "_uuid": "d787ba94e186ddb920b0c79011da69d15f00ce92"
   },
   "source": [
    "Iris Data Classification using a simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "e369e6ae-24d2-4496-81fc-b6c7f8504f76",
    "_execution_state": "idle",
    "_uuid": "2b30fc888ddacf28b086f8cffc7b50952e3b818f"
   },
   "outputs": [],
   "source": [
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "cd74bcac-f991-431c-bf2c-354922e175d2",
    "_execution_state": "idle",
    "_uuid": "30018f35d90c286acd7d75f049dca3f8ef40144e"
   },
   "outputs": [],
   "source": [
    "# Open the file for reading...\n",
    "df = pd.read_csv(r'C:\\Users\\aayus\\Desktop\\sim\\sim\\Iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "383010d9-3beb-47ae-af6c-9e4bc4931085",
    "_execution_state": "idle",
    "_uuid": "0a1315631dc29a3d3fdd8052dc3b76fa3ba791b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SepalLengthCm    0\n",
       "SepalWidthCm     0\n",
       "PetalLengthCm    0\n",
       "PetalWidthCm     0\n",
       "Species          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking drop/null values check\n",
    "df = df.drop(['Id'],axis=1)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "efcdcbe7-69b9-40b1-aecb-10d8a57149ce",
    "_execution_state": "idle",
    "_uuid": "0ba782108666e8f8c21cced2a99ee3a95a533e77"
   },
   "outputs": [],
   "source": [
    "df[\"Species\"] = df[\"Species\"].map({\n",
    "    \"Iris-setosa\": 0,\n",
    "    \"Iris-versicolor\": 1,\n",
    "    \"Iris-virginica\": 2\n",
    "}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "65b925c9-37fc-4faf-a14e-5dc0a56d8d9b",
    "_execution_state": "idle",
    "_uuid": "15d01db01c839fa7bd231a7e74f6a041a5da6dfa"
   },
   "outputs": [],
   "source": [
    "x_train = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
    "y_train = df['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "db37c288-014e-464f-a73a-570134689572",
    "_execution_state": "idle",
    "_uuid": "9b01dbcfb5b155c825b28b8c0b17c784a547f779"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aayus\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "new_y = []\n",
    "for i in y_train:\n",
    "    a = [0,0,0]\n",
    "    a[i] = 1\n",
    "    new_y.append(a)   \n",
    "    \n",
    "new_y\n",
    "columns = list(x_train)\n",
    "X = pd.DataFrame.as_matrix(x_train,columns=columns)\n",
    "Y = np.array(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "3605f966-1d8e-4f73-aa49-0800f75ed3c2",
    "_execution_state": "idle",
    "_uuid": "9a1ce35be409236475beb402bce664cd33257270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training (X):(4, 150)\n",
      "No of training (X):(3, 150)\n"
     ]
    }
   ],
   "source": [
    "#flatten the features for feeding into network base layer\n",
    "\n",
    "X_train_flatten = X.reshape(X.shape[0],-1).T\n",
    "Y_train_flatten = Y.reshape(Y.shape[0],-1).T\n",
    "print(\"No of training (X):\"+str(X_train_flatten.shape))\n",
    "print(\"No of training (X):\"+str(Y_train_flatten.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(YY_train_flatten).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize \n",
    "XX_train_flatten = normalize(X_train_flatten)\n",
    "YY_train_flatten = normalize(Y_train_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "e340e1b3-a10e-4a39-a559-7e0b65d43cc2",
    "_execution_state": "idle",
    "_uuid": "097a7ff49285b293f8fb4fb923fec89fa31f2ac5"
   },
   "outputs": [],
   "source": [
    "# creating the placeholders for X & Y \n",
    "def create_placeholders(n_x,n_y):\n",
    "    \n",
    "    X = tf.placeholder(shape=[n_x,None],dtype=tf.float32)\n",
    "    Y = tf.placeholder(shape=[n_y,None],dtype=tf.float32)\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape + Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "cf324953-f0db-4613-8885-6fc25e084daa",
    "_execution_state": "idle",
    "_uuid": "0ac10339d7e772031c13a36e8b813c8727de6c9d"
   },
   "outputs": [],
   "source": [
    "#initialize paramete \n",
    "def initialize_parameters():\n",
    "    \n",
    "    W1 = tf.get_variable(\"W1\",[2,4],initializer = tf.random_normal_initializer())#tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.get_variable(\"b1\",[2,1],initializer = tf.zeros_initializer())\n",
    "    W2 = tf.add(tf.math.scalar_mul(1.1,tf.get_variable(\"W2\",[3,2],initializer = tf.random_uniform_initializer())),-0.1)#tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.get_variable(\"b2\",[3,1],initializer = tf.zeros_initializer())\n",
    "    \n",
    "    parameters = {\"W1\":W1,\n",
    "                  \"b1\":b1,\n",
    "                  \"W2\":W2,\n",
    "                  \"b2\":b2}\n",
    "                  \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "b22b4ac2-7113-4a0c-8139-4af046b11b29",
    "_execution_state": "idle",
    "_uuid": "3731312be7a209d251492625f40f4ae53f16a089"
   },
   "outputs": [],
   "source": [
    "#forward propogation\n",
    "def forward_propagation(X, parameters):\n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']    \n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)\n",
    "    Z1 = tf.nn.relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,Z1),b2)\n",
    "    return Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "116a9ef5-15c5-474a-a616-80a86c938a48",
    "_execution_state": "idle",
    "_uuid": "a738d3a62d62beb6b67241ed723b248b74da0488"
   },
   "outputs": [],
   "source": [
    "# compute function \n",
    "def compute_cost(Z2,Y):\n",
    "    \n",
    "    logits = tf.transpose(Z2)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=labels))\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def compute_accuracy(Z2,Y):\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(Z2), tf.argmax(Y))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-b51a30f7120a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXX_train_flatten\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m       \u001b[1;31m# shape of X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mn_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_train_flatten\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m         \u001b[1;31m# shape of Y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_placeholders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_y\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# creating placeholder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitialize_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m            \u001b[1;31m# initialize parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-9638f46068a1>\u001b[0m in \u001b[0;36mcreate_placeholders\u001b[1;34m(n_x, n_y)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_placeholders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "# Running the NN !! \n",
    "#tf.reset_default_graph()\n",
    "(n_x, m) = XX_train_flatten.shape       # shape of X                    \n",
    "n_y = Y_train_flatten.shape[0]         # shape of Y\n",
    "X, Y = create_placeholders(n_x,n_y)    # creating placeholder \n",
    "tf.set_random_seed(42)\n",
    "p = initialize_parameters()            # initialize parameter \n",
    "Z6 = forward_propagation(X,p)          # forward prop\n",
    "y_softmax = tf.nn.softmax(Z6)          # softmax function \n",
    "cost = compute_cost(Z6,Y)              # cost function \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(cost)  # gradient descent, backprop, update,optimiz\n",
    "accuracy = compute_accuracy(Z6,Y)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())    #initializae \n",
    "par = sess.run(p)\n",
    "Y_pred = sess.run(Z6,feed_dict={X:XX_train_flatten})    #forward prop test \n",
    "cost_value = sess.run(cost,feed_dict={Z6:Y_pred,Y:Y_train_flatten})  #cost function test - First cost function \n",
    "costs =[]\n",
    "accuracies = []\n",
    "for i in range(0,5000):                # 2000 epoch !! \n",
    "    _,new_cost_value,new_acc_value = sess.run([optimizer, cost,accuracy], feed_dict={X: XX_train_flatten, Y: Y_train_flatten})\n",
    "    costs.append(new_cost_value)\n",
    "    accuracies += [new_acc_value]\n",
    "    \n",
    "p = sess.run(p)                        # parameter saving \n",
    "y_softmax = sess.run(y_softmax,feed_dict={X: XX_train_flatten})    # running softmax \n",
    "\n",
    "plt.plot(np.squeeze(costs))            # plot \n",
    "plt.plot(np.squeeze(accuracies))\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per tens)')\n",
    "plt.title(\"Learning rate =\" + str(.01))\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing prediction !! \n",
    "correct_prediction = tf.equal(tf.argmax(y_softmax), tf.argmax(Y_train_flatten))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(\"the Accuracy is :\"+str(sess.run(accuracy*100, feed_dict={X: XX_train_flatten, Y: Y_train_flatten})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = (XX_train_flatten.max(1)-XX_train_flatten.min(1))/10000\n",
    "dx[1:] = 0\n",
    "#X_temp = X_train_flatten-width.reshape(-1,1)\n",
    "#X_train_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = XX_train_flatten+dx.reshape(-1,1)\n",
    "Y_pred = sess.run(tf.nn.softmax(Z6),feed_dict={X:XX_train_flatten}).copy()\n",
    "Y_temp = sess.run(tf.nn.softmax(Z6),feed_dict={X:X_temp}).copy()\n",
    "dy = Y_temp-Y_pred\n",
    "a=(dy/dx[0]).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize paramete \n",
    "def initialize_parameters_2():\n",
    "    \n",
    "    W1 = tf.get_variable(\"W1\",[3,4],initializer = tf.zeros_initializer())#tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.get_variable(\"b1\",[3,1],initializer = tf.zeros_initializer())\n",
    "\n",
    "    \n",
    "    para_2 = {\"W1\":W1,\n",
    "                  \"b1\":b1}\n",
    "                  \n",
    "    return para_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward propogation\n",
    "def forward_propagation_2(X, parameters):\n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)\n",
    "\n",
    "    return Z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the NN !! \n",
    "tf.reset_default_graph()\n",
    "(n_x, m) = XX_train_flatten.shape       # shape of X                    \n",
    "n_y = Y_train_flatten.shape[0]         # shape of Y\n",
    "X, Y = create_placeholders(n_x,n_y)    # creating placeholder \n",
    "tf.set_random_seed(42)\n",
    "p = initialize_parameters_2()            # initialize parameter \n",
    "Z6 = forward_propagation_2(X,p)          # forward prop\n",
    "y_softmax = tf.nn.softmax(Z6)          # softmax function \n",
    "cost = compute_cost(Z6,Y)              # cost function\n",
    "accuracy = compute_accuracy(Z6,Y)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=2.2).minimize(cost)  # gradient descent, backprop, update,optimiz\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())    #initializae \n",
    "par = sess.run(p)\n",
    "Y_pred = sess.run(Z6,feed_dict={X:XX_train_flatten})    #forward prop test \n",
    "cost_value = sess.run(cost,feed_dict={Z6:Y_pred,Y:Y_train_flatten})  #cost function test - First cost function \n",
    "costs =[]\n",
    "accuracies = []\n",
    "for i in range(0,2000):                # 2000 epoch !! \n",
    "    _,new_cost_value,new_acc_value = sess.run([optimizer, cost, accuracy], feed_dict={X: XX_train_flatten, Y: Y_train_flatten})\n",
    "    costs.append(new_cost_value)\n",
    "    accuracies += [new_acc_value]\n",
    "\n",
    "p = sess.run(p)                        # parameter saving \n",
    "y_softmax = sess.run(y_softmax,feed_dict={X: XX_train_flatten})    # running softmax \n",
    "\n",
    "plt.plot(np.squeeze(costs))# plot\n",
    "plt.plot(np.squeeze(accuracies))\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per tens)')\n",
    "plt.title(\"Learning rate =\" + str(.01))\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing prediction !! \n",
    "correct_prediction = tf.equal(tf.argmax(y_softmax), tf.argmax(Y_train_flatten))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(\"the Accuracy is :\"+str(sess.run(accuracy*100, feed_dict={X: XX_train_flatten, Y: Y_train_flatten})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = (X_train_flatten.max(1)-X_train_flatten.min(1))/10000\n",
    "X_temp = X_train_flatten+dx.reshape(-1,1)\n",
    "Y_pred = sess.run(tf.nn.softmax(Z6),feed_dict={X:X_train_flatten})\n",
    "Y_temp = sess.run(tf.nn.softmax(Z6),feed_dict={X:X_temp})\n",
    "dy = Y_temp-Y_pred\n",
    "(dy/dx[0]).mean(1)\n",
    "(dy/dx[0]).mean(1)\n",
    "dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = XX_train_flatten+dx.reshape(-1,1)\n",
    "Y_pred = sess.run(tf.nn.softmax(Z6),feed_dict={X:XX_train_flatten}).copy()\n",
    "Y_temp = sess.run(tf.nn.softmax(Z6),feed_dict={X:X_temp}).copy()\n",
    "dy = Y_temp-Y_pred\n",
    "b=(dy/dx[0]).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(a-b)/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
